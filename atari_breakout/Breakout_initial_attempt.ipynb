{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78fec68a-c140-4cfe-88c6-91a454fcef62",
   "metadata": {},
   "source": [
    "# Atari Breakout in RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d76bd2-8a69-429c-bf5c-b0fca8cc9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ray[rllib]\n",
    "#!pip install ipywidgets gputil\n",
    "#!pip install gym[atari] autorom[accept-rom-license] ray[rllib] torch torchvision atari-py ale-py ale_py\n",
    "#!pip install \"gym[accept-rom-license, atari]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34c57b-d04e-443e-8145-24d99efa8c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 08:58:58,218\tINFO worker.py:1749 -- Started a local Ray instance.\n",
      "2024-04-26 08:58:58,805\tINFO tune.py:624 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-26 08:59:19</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:20.25        </td></tr>\n",
       "<tr><td>Memory:      </td><td>28.9/125.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 20.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_ALE_Breakout-v5_e4855_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=2682418)\u001b[0m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "\u001b[36m(RolloutWorker pid=2682418)\u001b[0m [Powered by Stella]\n",
      "2024-04-26 08:59:12,222\tWARNING logger.py:186 -- Remote file not found: /home/fitz/ray_results/PPO_2024-04-26_08-58-58/PPO_ALE_Breakout-v5_e4855_00000_0_2024-04-26_08-58-58/result.json\n",
      "\u001b[36m(PPO pid=2682269)\u001b[0m Restored on 192.168.1.114 from checkpoint: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-25_23-36-42/PPO_ALE_Breakout-v5_585c2_00000_0_2024-04-25_23-36-42/checkpoint_000184)\n",
      "\u001b[36m(PPO pid=2682269)\u001b[0m 2024-04-26 08:59:18,642\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=2682269)\u001b[0m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(PPO pid=2682269)\u001b[0m [Powered by Stella]\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics  </th><th>counters                                                                                                                                        </th><th>custom_metrics  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_timesteps_total</th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                                                                              </th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                               </th><th>timers                                                                                                                                                                                                                                                                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_ALE_Breakout-v5_e4855_00000</td><td style=\"text-align: right;\">               41005000</td><td>{}                 </td><td>{&#x27;num_env_steps_sampled&#x27;: 41005000, &#x27;num_env_steps_trained&#x27;: 41005000, &#x27;num_agent_steps_sampled&#x27;: 41005000, &#x27;num_agent_steps_trained&#x27;: 41005000}</td><td>{}              </td><td style=\"text-align: right;\">               nan</td><td>{}             </td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                  nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                         0</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;custom_metrics&#x27;: {}, &#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.0, &#x27;cur_lr&#x27;: 5e-05, &#x27;total_loss&#x27;: -0.01103209837092436, &#x27;policy_loss&#x27;: -0.007179453528951853, &#x27;vf_loss&#x27;: 0.004520092289312743, &#x27;vf_explained_var&#x27;: 0.9954019129276276, &#x27;kl&#x27;: 0.0043703861951019, &#x27;entropy&#x27;: 0.8372739440202713, &#x27;entropy_coeff&#x27;: 0.009999999999999998}, &#x27;model&#x27;: {}, &#x27;num_grad_updates_lifetime&#x27;: 50.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 49.5}}, &#x27;num_env_steps_sampled&#x27;: 41005000, &#x27;num_env_steps_trained&#x27;: 41005000, &#x27;num_agent_steps_sampled&#x27;: 41005000, &#x27;num_agent_steps_trained&#x27;: 41005000}</td><td style=\"text-align: right;\">                 41005000</td><td style=\"text-align: right;\">                 41005000</td><td style=\"text-align: right;\">               41005000</td><td style=\"text-align: right;\">                             5000</td><td style=\"text-align: right;\">                                   539.422</td><td style=\"text-align: right;\">               41005000</td><td style=\"text-align: right;\">                             5000</td><td style=\"text-align: right;\">                                   539.422</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   19</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         5000</td><td>{&#x27;cpu_util_percent&#x27;: 61.61538461538463, &#x27;ram_util_percent&#x27;: 21.00769230769231, &#x27;gpu_util_percent0&#x27;: 0.2876923076923077, &#x27;vram_util_percent0&#x27;: 0.18840895432692306}</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{}            </td><td>{&#x27;episode_reward_max&#x27;: nan, &#x27;episode_reward_min&#x27;: nan, &#x27;episode_reward_mean&#x27;: nan, &#x27;episode_len_mean&#x27;: nan, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 0, &#x27;episodes_timesteps_total&#x27;: 0, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [], &#x27;episode_lengths&#x27;: []}, &#x27;sampler_perf&#x27;: {}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {}}</td><td>{&#x27;training_iteration_time_ms&#x27;: 9269.195, &#x27;restore_workers_time_ms&#x27;: 0.017, &#x27;training_step_time_ms&#x27;: 9269.148, &#x27;sample_time_ms&#x27;: 6348.208, &#x27;load_time_ms&#x27;: 100.959, &#x27;load_throughput&#x27;: 49525.258, &#x27;learn_time_ms&#x27;: 2786.206, &#x27;learn_throughput&#x27;: 1794.555, &#x27;synch_weights_time_ms&#x27;: 30.868}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 08:59:21,571\tWARNING logger.py:186 -- Remote file not found: /home/fitz/ray_results/PPO_2024-04-26_08-58-58/PPO_ALE_Breakout-v5_e4855_00000_0_2024-04-26_08-58-58/progress.csv\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "from ray import tune\n",
    "import ale_py\n",
    "\n",
    "\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(num_cpus=20, num_gpus=1)\n",
    "    #env = gym.make(\"ALE/Breakout-v5\")\n",
    "\n",
    "checkpoint_directory = '/home/fitz/ray_results/PPO_2024-04-25_23-36-42/PPO_ALE_Breakout-v5_585c2_00000_0_2024-04-25_23-36-42/checkpoint_000184'\n",
    "config = {\n",
    "    \"env\": \"ALE/Breakout-v5\",\n",
    "    \"num_workers\": 19,\n",
    "    \"num_envs_per_worker\": 4,\n",
    "    \"num_gpus\": 1,\n",
    "    \"framework\": \"torch\",  \n",
    "    \"gamma\": 0.99,\n",
    "    \"train_batch_size\": 5000,\n",
    "    \"rollout_fragment_length\": \"auto\",\n",
    "    \"sgd_minibatch_size\": 500,\n",
    "    \"num_sgd_iter\": 10,\n",
    "    \"clip_param\": 0.1,\n",
    "    \"entropy_coeff\": 0.01,\n",
    "    \"batch_mode\": \"truncate_episodes\",\n",
    "    \"lambda\": 0.95,\n",
    "    \"kl_coeff\": 0.5,\n",
    "    \"clip_rewards\": True,\n",
    "    \"clip_param\": 0.1,\n",
    "    \"vf_clip_param\": 10.0,\n",
    "    \"entropy_coeff\": 0.01,\n",
    "}\n",
    "\n",
    "\n",
    "#config = {\n",
    "#        \"env\": \"ALE/Breakout-v5\",\n",
    "#        \"preprocessor_pref\": None,\n",
    "#   #     \"gamma\": 0.99,\n",
    "#  #      \"num_gpus\": 1,\n",
    "# #       \"num_workers\": 19,\n",
    "##        \"num_envs_per_worker\": 4,\n",
    "#        \"create_env_on_driver\": True,\n",
    "#        \"lambda\": 0.95,\n",
    "#        \"kl_coeff\": 0.5,\n",
    "#        \"clip_rewards\": True,\n",
    "#        \"clip_param\": 0.1,\n",
    "#        \"vf_clip_param\": 10.0,\n",
    "#        \"entropy_coeff\": 0.01,\n",
    "##        \"rollout_fragment_length\": \"auto\",\n",
    "##        \"sgd_minibatch_size\": 500,\n",
    "##        \"num_sgd_iter\": 10,\n",
    "##        \"batch_mode\": \"truncate_episodes\",\n",
    "##        \"framework\": \"torch\",\n",
    "#}\n",
    "\n",
    "stop_criteria = {\n",
    "    \"training_iteration\": 15000,\n",
    "    \"episode_reward_mean\": 200\n",
    "}\n",
    "\n",
    "results = tune.run(\n",
    "    \"PPO\",\n",
    "    config=config,\n",
    "    stop=stop_criteria,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=20,\n",
    "    keep_checkpoints_num=20,  # Keep 10 checkpoints\n",
    "    checkpoint_score_attr=\"episode_reward_mean\",  # Retain checkpoints with the highest episode rewards\n",
    "    restore=checkpoint_directory\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c477aa-69b6-4401-82e5-3f9205cee8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-25_23-36-42/PPO_ALE_Breakout-v5_585c2_00000_0_2024-04-25_23-36-42/checkpoint_000184)\n"
     ]
    }
   ],
   "source": [
    "best_trial = results.get_best_trial(\"episode_reward_mean\", \"max\", \"last\")\n",
    "best_checkpoint = results.get_best_checkpoint(best_trial, \"episode_reward_mean\", \"max\")\n",
    "print(\"Best checkpoint:\", best_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c75591-821c-4243-af52-9bf8c80082bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae5c0c-3c9d-4abe-b2db-aae195118505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
