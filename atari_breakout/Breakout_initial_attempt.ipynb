{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78fec68a-c140-4cfe-88c6-91a454fcef62",
   "metadata": {},
   "source": [
    "# Atari Breakout in RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d76bd2-8a69-429c-bf5c-b0fca8cc9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ray[rllib]\n",
    "#!pip install ipywidgets gputil\n",
    "#!pip install gym[atari] autorom[accept-rom-license] ray[rllib] torch torchvision atari-py ale-py ale_py\n",
    "#!pip install \"gym[accept-rom-license, atari]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34c57b-d04e-443e-8145-24d99efa8c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 22:54:46,451\tINFO worker.py:1749 -- Started a local Ray instance.\n",
      "2024-04-24 22:54:46,996\tINFO tune.py:624 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-24 23:32:08</td></tr>\n",
       "<tr><td>Running for: </td><td>00:37:21.99        </td></tr>\n",
       "<tr><td>Memory:      </td><td>19.5/125.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 20.0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_ALE_Breakout-v5_52587_00000</td><td>RUNNING </td><td>10.5.0.2:104365</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         2174.61</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">    2.23</td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">            233.48</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=104524)\u001b[0m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "\u001b[36m(RolloutWorker pid=104524)\u001b[0m [Powered by Stella]\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m 2024-04-24 22:55:07,681\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m [Powered by Stella]\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics  </th><th>counters                                                                                                                                </th><th>custom_metrics  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_timesteps_total</th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                                                                                </th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th>timers                                                                                                                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_ALE_Breakout-v5_52587_00000</td><td style=\"text-align: right;\">                 140000</td><td>{}                 </td><td>{&#x27;num_env_steps_sampled&#x27;: 140000, &#x27;num_env_steps_trained&#x27;: 140000, &#x27;num_agent_steps_sampled&#x27;: 140000, &#x27;num_agent_steps_trained&#x27;: 140000}</td><td>{}              </td><td style=\"text-align: right;\">            233.48</td><td>{}             </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">                 2.23</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  28</td><td style=\"text-align: right;\">                     23348</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 1.2862201324105262, &#x27;cur_kl_coeff&#x27;: 9.765624999999998e-05, &#x27;cur_lr&#x27;: 5e-05, &#x27;total_loss&#x27;: 0.01019454746725387, &#x27;policy_loss&#x27;: -0.0024429959803819656, &#x27;vf_loss&#x27;: 0.023546788645908236, &#x27;vf_explained_var&#x27;: 0.9033010703325272, &#x27;kl&#x27;: 0.00874496490592719, &#x27;entropy&#x27;: 1.091010309457779, &#x27;entropy_coeff&#x27;: 0.009999999999999998}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 500.0, &#x27;num_grad_updates_lifetime&#x27;: 2750.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 49.5}}, &#x27;num_env_steps_sampled&#x27;: 140000, &#x27;num_env_steps_trained&#x27;: 140000, &#x27;num_agent_steps_sampled&#x27;: 140000, &#x27;num_agent_steps_trained&#x27;: 140000}</td><td style=\"text-align: right;\">                   140000</td><td style=\"text-align: right;\">                   140000</td><td style=\"text-align: right;\">                 140000</td><td style=\"text-align: right;\">                             5000</td><td style=\"text-align: right;\">                                   64.7339</td><td style=\"text-align: right;\">                 140000</td><td style=\"text-align: right;\">                             5000</td><td style=\"text-align: right;\">                                   64.7339</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   19</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         5000</td><td>{&#x27;cpu_util_percent&#x27;: 19.645192307692305, &#x27;ram_util_percent&#x27;: 15.218269230769234, &#x27;gpu_util_percent0&#x27;: 0.1782692307692308, &#x27;vram_util_percent0&#x27;: 0.05781250000000001}</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 2.163045805872632, &#x27;mean_inference_ms&#x27;: 37.33256771678569, &#x27;mean_action_processing_ms&#x27;: 0.3599760439198613, &#x27;mean_env_wait_ms&#x27;: 4.812104832964616, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 4.0, &#x27;episode_reward_min&#x27;: 0.0, &#x27;episode_reward_mean&#x27;: 2.23, &#x27;episode_len_mean&#x27;: 233.48, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 28, &#x27;episodes_timesteps_total&#x27;: 23348, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 2.0, 0.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 4.0, 2.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 2.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 0.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 4.0, 2.0], &#x27;episode_lengths&#x27;: [216, 232, 222, 308, 199, 227, 266, 266, 225, 211, 212, 270, 203, 325, 314, 179, 219, 135, 304, 265, 234, 274, 276, 256, 227, 155, 223, 258, 329, 302, 130, 234, 310, 225, 204, 205, 225, 156, 300, 228, 270, 207, 303, 209, 333, 218, 329, 145, 310, 146, 143, 132, 279, 214, 255, 281, 131, 225, 279, 154, 263, 148, 204, 307, 313, 230, 217, 208, 223, 222, 257, 211, 271, 211, 138, 219, 276, 263, 319, 261, 324, 275, 144, 263, 230, 266, 217, 227, 205, 150, 213, 143, 280, 159, 215, 328, 145, 137, 321, 233]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 2.163045805872632, &#x27;mean_inference_ms&#x27;: 37.33256771678569, &#x27;mean_action_processing_ms&#x27;: 0.3599760439198613, &#x27;mean_env_wait_ms&#x27;: 4.812104832964616, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {}}</td><td>{&#x27;training_iteration_time_ms&#x27;: 77620.642, &#x27;restore_workers_time_ms&#x27;: 0.018, &#x27;training_step_time_ms&#x27;: 77620.596, &#x27;sample_time_ms&#x27;: 12297.427, &#x27;load_time_ms&#x27;: 1.531, &#x27;load_throughput&#x27;: 3265777.999, &#x27;learn_time_ms&#x27;: 65298.441, &#x27;learn_throughput&#x27;: 76.572, &#x27;synch_weights_time_ms&#x27;: 22.961}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=104365)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-24_22-54-47/PPO_ALE_Breakout-v5_52587_00000_0_2024-04-24_22-54-47/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-24_22-54-47/PPO_ALE_Breakout-v5_52587_00000_0_2024-04-24_22-54-47/checkpoint_000001)\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-24_22-54-47/PPO_ALE_Breakout-v5_52587_00000_0_2024-04-24_22-54-47/checkpoint_000002)\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-24_22-54-47/PPO_ALE_Breakout-v5_52587_00000_0_2024-04-24_22-54-47/checkpoint_000003)\n",
      "\u001b[36m(PPO pid=104365)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-24_22-54-47/PPO_ALE_Breakout-v5_52587_00000_0_2024-04-24_22-54-47/checkpoint_000004)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "from ray import tune\n",
    "import ale_py\n",
    "\n",
    "\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(num_cpus=20)\n",
    "    #env = gym.make(\"ALE/Breakout-v5\")\n",
    "\n",
    "checkpoint_directory = '/home/fitz/ray_results/PPO_2024-04-24_22-45-18/PPO_ALE_Breakout-v5_ff415_00000_0_2024-04-24_22-45-18/checkpoint_000004'\n",
    "config = {\n",
    "    \"env\": \"ALE/Breakout-v5\",\n",
    "    \"num_workers\": 19,  \n",
    "    \"framework\": \"torch\",  \n",
    "    \"gamma\": 0.99,\n",
    "    \"train_batch_size\": 5000,\n",
    "    \"rollout_fragment_length\": \"auto\",\n",
    "    \"sgd_minibatch_size\": 500,\n",
    "    \"num_sgd_iter\": 10,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"entropy_coeff\": 0.01,\n",
    "}\n",
    "\n",
    "stop_criteria = {\n",
    "    \"training_iteration\": 300,\n",
    "    \"episode_reward_mean\": 200\n",
    "}\n",
    "\n",
    "results = tune.run(\n",
    "    \"PPO\",\n",
    "    config=config,\n",
    "    stop=stop_criteria,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=5,\n",
    "    keep_checkpoints_num=10,  # Keep 10 checkpoints\n",
    "    checkpoint_score_attr=\"episode_reward_mean\",  # Retain checkpoints with the highest episode rewards\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c477aa-69b6-4401-82e5-3f9205cee8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: Checkpoint(filesystem=local, path=/home/fitz/ray_results/PPO_2024-04-24_22-45-18/PPO_ALE_Breakout-v5_ff415_00000_0_2024-04-24_22-45-18/checkpoint_000004)\n"
     ]
    }
   ],
   "source": [
    "best_trial = results.get_best_trial(\"episode_reward_mean\", \"max\", \"last\")\n",
    "best_checkpoint = results.get_best_checkpoint(best_trial, \"episode_reward_mean\", \"max\")\n",
    "print(\"Best checkpoint:\", best_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c75591-821c-4243-af52-9bf8c80082bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d25f45-7493-4ae3-912f-9cab0d40d09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
